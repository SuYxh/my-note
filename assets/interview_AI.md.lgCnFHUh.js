import{_ as a,c as t,o as e,V as i}from"./chunks/framework.hxTji2_l.js";const q=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"interview/AI.md","filePath":"interview/AI.md","lastUpdated":1716648538000}'),n={name:"interview/AI.md"},r=i('<h2 id="chatgpt原理" tabindex="-1">ChatGPT原理 <a class="header-anchor" href="#chatgpt原理" aria-label="Permalink to &quot;ChatGPT原理&quot;">​</a></h2><p>好的，让我们通过一个具体的例子来详细解释 ChatGPT 如何理解和生成文本的过程。</p><p>示例：用户输入 &quot;今天天气怎么样？&quot;</p><ol><li><strong>输入处理与编码</strong></li></ol><ul><li><strong>文本转换为数字</strong>：首先，&quot;今天天气怎么样？&quot; 这句话会被分解成单词或汉字，并转换为数字表示（嵌入向量）。例如，&quot;今天&quot;、&quot;天气&quot;、&quot;怎么样&quot; 和 &quot;？&quot; 每一个都被转换成一个向量。</li><li><strong>自注意力机制</strong>：接下来，模型的自注意力层会处理这些向量。这一机制允许模型关注输入句子中的所有部分（即使是非相邻的部分）。例如，它可以强化“今天”和“天气”之间的联系，从而理解这是一个关于当前天气状况的询问。</li></ul><ol start="2"><li><strong>文本生成与解码</strong></li></ol><ul><li><strong>逐词生成响应</strong>：解码器开始逐词生成回答。假设首个生成的词是&quot;晴朗&quot;，解码器会在生成下一个词之前考虑已生成的&quot;晴朗&quot;。</li><li><strong>继续生成</strong>：模型可能接着生成&quot;，&quot;（逗号），然后是&quot;适合&quot;、&quot;出门&quot;，最后是&quot;。&quot;（句号），形成一个完整的回答：&quot;晴朗，适合出门。&quot;</li><li><strong>保持连贯性</strong>：在这个过程中，每一步的词汇选择都考虑到了前面的语境。模型会评估哪些词在语义上和语法上最适合接在前面的词后面。</li></ul><ol start="3"><li><strong>预训练和微调</strong></li></ol><ul><li><strong>广泛的训练数据</strong>：在用户交互之前，ChatGPT 已经通过大量的文本（包括对话、新闻、书籍等）进行预训练，这帮助它学习了语言的广泛用法和模式。</li><li><strong>微调</strong>：为了更好地适应特定任务（比如天气信息提供），ChatGPT 可以通过更特定的对话数据进行微调，这使得它在相似问题上的回答更为准确和自然。</li></ul><p>优化和挑战</p><p>尽管 ChatGPT 在处理这类任务时表现出色，但它仍然面临一些挑战，如对话的一致性、对特定背景知识的依赖等。此外，它可能生成不精确或不相关的回答，特别是在处理非常具体或复杂的问题时。</p><p>以上就是 ChatGPT 理解和生成文本的一个详细案例，希望这可以帮助你更好地理解其工作原理和过程。如果你有其他关于这个过程的问题或想要探讨的其他方面，请随时告诉我！</p><h2 id="rag-retrieval-augmented-generation" tabindex="-1">RAG（Retrieval-Augmented Generation） <a class="header-anchor" href="#rag-retrieval-augmented-generation" aria-label="Permalink to &quot;RAG（Retrieval-Augmented Generation）&quot;">​</a></h2><p>RAG是一种模型架构，结合了检索（retrieval）和生成（generation）的方法。它使用检索模块从大规模的知识库中检索相关信息，然后使用生成模块生成响应或回答。这种结合检索和生成的方法可以提高模型的语言理解和生成能力。</p><p>RAG的主要应用场景是问答系统和对话系统。它可以用于构建智能问答机器人、聊天机器人和虚拟助手等，使其能够更好地理解用户的问题，并生成准确和有意义的回答。</p><h2 id="agi-artificial-general-intelligence" tabindex="-1">AGI（Artificial General Intelligence） <a class="header-anchor" href="#agi-artificial-general-intelligence" aria-label="Permalink to &quot;AGI（Artificial General Intelligence）&quot;">​</a></h2><p>AGI是指人工通用智能，也称为强人工智能。它指的是具有与人类智能相似的广泛认知能力和智能水平的人工智能系统。AGI的目标是能够在各种任务和领域中进行通用的智能表现，具备学习、推理、解决问题和适应环境等能力。</p><p>AGI的应用场景非常广泛，可以应用于自动驾驶、自动化生产、医疗诊断、智能机器人等领域。它可以在各种复杂任务中代替人类工作，实现更高效和准确的智能表现。</p><h2 id="aigc-ai-guided-creativity" tabindex="-1">AIGC（AI-Guided Creativity） <a class="header-anchor" href="#aigc-ai-guided-creativity" aria-label="Permalink to &quot;AIGC（AI-Guided Creativity）&quot;">​</a></h2><p>AIGC是指人工智能引导的创造力。它结合了人工智能技术和创造性思维，旨在通过AI的辅助和增强来推动创造力的发展。</p><p>AIGC的应用场景包括艺术、设计、创意产业和创新研发等领域。在艺术领域，AI可以用于生成音乐、绘画和写作等创作内容，与艺术家合作创作。在设计领域，AI可以辅助设计师进行创意设计、自动化生成设计方案，提供灵感和创意推动。</p><p>总的来说，RAG是一种模型架构，用于问答和对话系统，AGI是人工通用智能的概念，具备广泛的智能能力，而AIGC是指人工智能引导的创造力，在艺术、设计和创新领域具有应用潜力。</p><h2 id="多模态" tabindex="-1">多模态 <a class="header-anchor" href="#多模态" aria-label="Permalink to &quot;多模态&quot;">​</a></h2><p>多模态 AI 合并了许多数据模态，例如文本、照片、视频和音频，以提供对场景的更透彻的理解。多模式 AI 的目标是从多个来源编译数据，以支持更准确和可信的决策。</p><p>多模式 AI 可以通过融合多种模式并为消费者提供更自然、更直观的技术参与方式来提高机器学习模型的效力。</p><p>多模态 AI 的优势在于它能够超越单模态数据的限制，并提供对困难情况的更全面理解。</p><p>多模态人工智能 (AI) 有能力改变人们在现实世界中与技术互动和决策的方式，并在医疗保健、交通、教育、营销和娱乐等一系列行业中应用。</p><h2 id="langchain" tabindex="-1">LangChain <a class="header-anchor" href="#langchain" aria-label="Permalink to &quot;LangChain&quot;">​</a></h2><p>LangChain 是一个开源框架，专为开发由大型语言模型（LLMs）驱动的应用而设计。它通过提供一系列模块化的构建块和工具，简化了人工智能应用的开发流程。</p><h3 id="核心组件" tabindex="-1">核心组件 <a class="header-anchor" href="#核心组件" aria-label="Permalink to &quot;核心组件&quot;">​</a></h3><ol><li><p><strong>Chains 和 Agents</strong>：</p><ul><li><strong>Chains</strong> 是一系列自动化动作的集合，从用户的查询到模型的输出。这些动作包括格式化用户输入、发送查询、检索数据等。</li><li><strong>Agents</strong> 是特殊类型的 Chains，它们可以根据用户输入决定调用哪些工具。Agents 能够处理更复杂的应用场景，比如同时与多个数据源或工具交互。</li></ul></li><li><p><strong>LangChain Expression Language (LCEL)</strong>：</p><ul><li>LCEL 提供了一种声明式方法来组合 Chains，支持从最简单的配置到最复杂的多步骤应用。</li></ul></li><li><p><strong>Modules</strong>：</p><ul><li>LangChain 提供多种模块，包括模型输入/输出、数据检索、结构化输出解析等。这些模块可以自由组合，以支持不同的应用需求。</li></ul></li></ol><h3 id="工作流程" tabindex="-1">工作流程 <a class="header-anchor" href="#工作流程" aria-label="Permalink to &quot;工作流程&quot;">​</a></h3><p>LangChain 通过整合不同的模块和工具，允许开发者构建复杂的应用。例如，可以创建一个基于检索增强生成（RAG）的工作流程，这不仅可以减少模型产生错误信息的情况，还可以提高回答的准确性。此外，LangChain 支持与外部数据源的连接，如通过 Apify Actors 进行网页抓取，并将数据直接输入到 LangChain 的向量数据库中，这样可以构建类似 ChatGPT 的查询接口【8†source】【9†source】【10†source】【12†source】【13†source】。</p><h3 id="实用场景" tabindex="-1">实用场景 <a class="header-anchor" href="#实用场景" aria-label="Permalink to &quot;实用场景&quot;">​</a></h3><p>LangChain 可应用于多种场景，如问答系统、聊天机器人、文档分析、API交互、代码理解和生成、以及自动化代理模拟等。此外，它还可以用于构建多模态输出应用，例如同时处理文本、图像和其他类型数据的系统【8†source】【9†source】。</p><h3 id="开发支持与生态系统" tabindex="-1">开发支持与生态系统 <a class="header-anchor" href="#开发支持与生态系统" aria-label="Permalink to &quot;开发支持与生态系统&quot;">​</a></h3><p>LangChain 由一个活跃的社区支持，提供了广泛的开发工具和集成选项，使开发者可以自由扩展和定制应用。LangChain 的生态系统还包括 LangSmith、LangGraph 和 LangServe 等工具，用于调试、测试、评估和部署应用【8†source】【9†source】。</p><p>总之，LangChain 为开发者提供了一个强大而灵活的框架，用于开发和部署基于语言模型的智能应用，其模块化的设计和丰富的集成选项使得它适用于各种复杂的业务场景。</p><p>在我们有了 langchain 后，chat bot 不止是一个简单的调 API 的任务，而且通过管理 prompt、多 llm 协同而成的一个工程任务。</p><h2 id="大模型问题" tabindex="-1">大模型问题 <a class="header-anchor" href="#大模型问题" aria-label="Permalink to &quot;大模型问题&quot;">​</a></h2><p>对领域知识的欠缺。这部分分两种情况，第一种是对知识的更新慢，例如你问他最新的新闻他肯定是不知道的，因为他的训练数据集不可能每天更新；第二种是特定领域的知识不了解，例如你要创建一个宠物医疗 chat bot，他本身训练数据集这方面的知识占比肯定是少的，就很容易出现幻想问题，然后瞎回答。更不要说公司内部的知识库了。所以，RAG 就是针对这两点进行解决的。</p><h2 id="难点" tabindex="-1">难点 <a class="header-anchor" href="#难点" aria-label="Permalink to &quot;难点&quot;">​</a></h2><p><img src="https://qn.huat.xyz/mac/202405252244863.png" alt="image-20240525224436621"></p>',43),o=[r];function l(h,s,u,g,p,c){return e(),t("div",null,o)}const A=a(n,[["render",l]]);export{q as __pageData,A as default};
